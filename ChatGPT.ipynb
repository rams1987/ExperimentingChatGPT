{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPSSWvsZk7F4ilsBCdmnAmQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rams1987/ExperimentingChatGPT/blob/main/ChatGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjJ84NVJOdsE",
        "outputId": "fb060a7a-4c2b-49db-bd57-8b59a8d21148"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def extract_text_from_image(image_path):\n",
        "    # Load the image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "    # Convert the image to grayscale\n",
        "    #gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Use pytesseract to perform OCR\n",
        "    #extracted_text = pytesseract.image_to_string(gray_image)\n",
        "    return image"
      ],
      "metadata": {
        "id": "nCLO7MI6Q546"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "api_key = \"\"\n",
        "openai.api_key = api_key\n",
        "\n",
        "# Define a function to interact with ChatGPT-4\n",
        "def ask_chatgpt_4(prompt, max_tokens=150, temperature=0.7):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",  # Use ChatGPT-4 (Davinci)\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "image_path = \"./img1.jpg\"\n",
        "\n",
        "# Extract text from the image\n",
        "image_text = extract_text_from_image(image_path)\n",
        "\n",
        "# Example description of the image\n",
        "image_description = \"Image taken in a retail store\"\n",
        "\n",
        "# Additional text to provide context\n",
        "additional_text = \"Can you analyze this image?\"\n",
        "\n",
        "# Generate the prompt\n",
        "prompt = f\"{additional_text}\\n{image_description}\"\n",
        "\n",
        "\n",
        "# Additional text to provide context\n",
        "#prompt = \"Can you describe the contents of this image?\"\n",
        "\n",
        "# Example prompt\n",
        "#prompt = \"Q: What is the meaning of life?\\nA: The meaning of life is\"\n",
        "\n",
        "# Get ChatGPT-4's completion\n",
        "response = ask_chatgpt_4(prompt)\n",
        "\n",
        "# Print the response\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GgBwc7fQO0y",
        "outputId": "f1aaaf6c-4c0a-4271-c32e-dae6d24ea275"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I'm not able to analyze images. However, I can help you with information or answer questions about retail stores based on text descriptions. If you provide more details or describe the image, I'd be happy to assist you further!\n"
          ]
        }
      ]
    }
  ]
}